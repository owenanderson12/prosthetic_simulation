# EEG-Controlled Prosthetic Hand Simulation Plan

This document outlines the implementation of a real-time system that enables EEG-based control of a simulated prosthetic hand. The system will use motor imagery signals processed from an EEG device to classify left vs. right hand imagery and control corresponding movements in a Unity-based hand simulation.

## Configuration Parameters

- Window size: 2.0 seconds (sliding window for continuous processing)
- Window overlap: 0.5 seconds (75% overlap for smoother control)
- Sampling rate: 250 Hz
- Frequency bands of interest: Mu (8-13 Hz), Beta (13-30 Hz)
- Classifier threshold: 0.65 (confidence level required for actuation)
- Buffer size: 2500 samples (10 seconds at 250Hz)
- Channels of interest: C3, CP1 (left hemisphere), C4, CP2 (right hemisphere)
- Calibration period: 60 seconds (to establish baseline and individual ERD patterns)
- Connection timeout: 10 seconds (for LSL stream reconnection attempts)

## System Architecture

### Main Script (prosthetic_control.py)
- Initialize system components and configuration
- Establish LSL streams connection
- Manage main control loop
- Handle user interface and feedback
- Error handling and logging
- Graceful shutdown procedures

### Modules

#### 1. Data Acquisition (modules/eeg_acquisition.py)
- Resolve and connect to LSL EEG stream (Cyton board)
- Implement buffering mechanism for EEG data
- Handle connection interruptions
- Implement signal quality checks
- Provide timestamps for synchronization

#### 2. Signal Processing (modules/signal_processor.py)
- Apply spatial filtering (CAR, bipolar derivations)
- Bandpass filtering (1-40 Hz)
- Artifact rejection
- Feature extraction
  - Band power calculation (mu and beta bands)
  - ERD/ERS quantification
  - CSP features for left vs. right discrimination
- Normalization relative to calibration baseline

#### 3. Classification (modules/classifier.py)
- Implement pre-trained classifier (LDA with shrinkage)
- Continuous probability estimation
- State machine for decision smoothing
- Adaptive thresholding based on performance
- Confidence estimation
- Rejection of uncertain classifications

#### 4. Simulation Interface (modules/simulation_interface.py)
- Establish and maintain LSL output stream to Unity
- Translate classifier output to hand movement commands
- Implement control mappings:
  - Left hand imagery → opening/closing of hand
  - Right hand imagery → wrist rotation
  - Idle state → maintain position
- Generate appropriate LSL markers for simulation events
- Handle simulation feedback

#### 5. Calibration System (modules/calibration.py)
- Guided calibration procedure
- Collection of baseline/resting state
- Collection of left and right motor imagery examples
- Quick classifier training
- Parameter optimization
- Saving/loading calibration profiles

#### 6. Visualization (modules/visualization.py)
- Real-time EEG visualization
- Band power visualization
- Classification confidence display
- System status indicators
- Performance metrics display

## Implementation Flow

1. **Startup Phase**
   - Load configuration
   - Establish LSL connections
   - Validate hardware connectivity
   - Load pre-trained classifier or prompt for calibration

2. **Calibration Phase (if needed)**
   - Guide user through calibration procedure
   - Collect baseline and task data
   - Train initial classifier
   - Validate classifier performance

3. **Operation Phase**
   - Continuous data acquisition
   - Real-time signal processing in sliding windows
   - Classification of motor imagery state
   - Translation to simulation commands
   - Feedback visualization
   - Performance monitoring

4. **Adaptation Phase**
   - Periodic recalibration as needed
   - Adaptive thresholding based on performance
   - User-specific parameter adjustments

## Unity Integration Details

- Unity scene with realistic hand model
- LSL input stream consumer script
- Smooth interpolation of movements
- Visual feedback mechanisms
- State visualization (resting, left imagery, right imagery)
- Performance metrics display
- Practice mode with guided exercises

## Performance Considerations

- Minimize processing latency (<100ms desired)
- Ensure reliable classification (>75% accuracy target)
- Balance responsiveness vs. stability (debouncing)
- Handle noisy input gracefully
- Provide clear feedback on system state

## Testing Protocol

1. System validation with pre-recorded data
2. Closed-loop testing with developers
3. User testing with novice subjects
4. Quantitative performance assessment
   - Classification accuracy
   - Time to action
   - False positive rate
   - User satisfaction metrics

## Next Steps

1. Implement data acquisition module
2. Test real-time signal processing pipeline
3. Integrate pre-trained classifier from offline analysis
4. Develop simple Unity hand simulation
5. Establish LSL communication between components
6. Implement basic end-to-end functionality
7. Add calibration functionality
8. Enhance visualization and feedback
9. Optimize for performance
10. Conduct user testing